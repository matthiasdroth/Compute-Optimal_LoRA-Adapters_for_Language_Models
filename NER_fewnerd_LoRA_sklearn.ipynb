{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f55bab0",
   "metadata": {},
   "source": [
    "- *It works!*\n",
    "- DONE: use `max_batchsize` from `utils`\n",
    "- DONE: make **dedicated notebook** to (i) compare `conll2003` to `fewnerd` and (ii) to bring `fewnerd` into the same format.\n",
    "- DONE: use fewnerd\n",
    "- DONE: get total flops count with **einops**\n",
    "- DONE: make custom splits\n",
    "- DONE: reorder the notebook cells:\n",
    "  - DONE: model (LoRA) and tokenizer (save peftconfig if necessary)\n",
    "  - DONE: dataset etc\n",
    "  - DONE: training, metrics and saving (tokenizer and model)\n",
    "  - DONE: inference via loading saved items (probably tokenizer, model and peftconfig – OR follow this [guide](https://huggingface.co/docs/peft/v0.9.0/en/package_reference/lora#peft.LoraModel))\n",
    "- DONE: In **Using the fine-tuned model**, [merge and unload](https://huggingface.co/docs/peft/v0.6.2/en/package_reference/tuners#peft.LoraModel.merge_and_unload) or [reinstantiate](https://huggingface.co/docs/peft/v0.6.2/en/task_guides/token-classification-lora#inference) the LoRA model!\n",
    "- DONE: adjust batch size – and if necessary epochs – for 3000 training steps `num_steps = train_instances*epochs/batch_size` $\\geq$ 3000 $\\Rightarrow$ `batch_size` $\\leq$ `train_instances*epochs/3000 = train_instances/1000` $\\Rightarrow$ `batch_size` $\\leq$ `train_instances / 1000` for `epochs = 3`<br>DONE: But do it like this:\n",
    "  - DONE: get max batch size for model (= max_batchsize_by_model)\n",
    "  - DONE: specify trainig split\n",
    "  - DONE: get max batch size for training split length (=max_batchsize_by_trainsplit)\n",
    "  - DONE: impose max batch size of 32\n",
    "  - DONE: the batch size is the minimum of these three numbers\n",
    "- DONE: build `results.json` (consider pandas series) via dict. It holds: splits, specified loraconfig details, flops, metrics (per epoch)\n",
    "- DONE: use the uuid library to save `results.json` under `results_{uuid}.json`\n",
    "- DONE: declare variable `split` and use it to select splits as well as for logging it in `results_{uuid}.json`.\n",
    "- DONE: use split `dev` and determine the learning rate for LoRA models. It seems that with `accelerate`, the maximum accepted learning rate is `5e-4` since fails for higher learning rates.\n",
    "- DONE: outside the training loop make a dummy classification report using scikit-learn with dummy labels and dummy predictions (both formatted as required by classification report)\n",
    "- DONE: at the end of each epoch, bring the labels and predictions into the required format\n",
    "- DONE: write a compute metrics function that returns a [classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report) as dict, then log the relevant values\n",
    "- DONE: drop the `uuid` from the `logs_dict` filename as it only adds ambiguity about what file to look at.\n",
    "- check everything once more\n",
    "- add comments\n",
    "- make new notebook copy for sweep\n",
    "- Check once more the wandb [ablation study](https://wandb.ai/ayush-thakur/dl-question-bank/reports/What-s-the-Optimal-Batch-Size-to-Train-a-Neural-Network---VmlldzoyMDkyNDU) on batch sizes!\n",
    "\n",
    "# NER with `fewnerd` and LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6a8a50f-42a6-4597-b1b5-69d765923b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn==1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c02c47-b51b-4e13-8d3d-01dacf934f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b4b5296-cb60-4875-a7f3-96e2c0c03fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-14 21:31:31,300] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/matthias/.cache/huggingface/token\n",
      "Login successful\n",
      "All random seeds set to 42.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "from peft import LoraConfig, TaskType, PeftModel, PeftConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "#from uuid import uuid4\n",
    "from utils import set_seed, make_confusion_matrix\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
    "from evaluate import load\n",
    "from tqdm.auto import tqdm\n",
    "from accelerate import Accelerator\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler, pipeline, AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification\n",
    "from huggingface_hub import login\n",
    "from sklearn.metrics import classification_report # version 1.3.2 works\n",
    "from torch.utils.data import DataLoader\n",
    "from deepspeed.profiling.flops_profiler import FlopsProfiler\n",
    "\n",
    "load_dotenv()\n",
    "login(token=os.getenv(\"HUGGINGFACE_API_KEY\"))\n",
    "logs_dict = {}\n",
    "logs_dict[\"seed\"] = set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9864ca-1c11-44bd-8bf5-b1db6cb243d5",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f272eac3-45d7-4b20-99d7-2da88507b515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b5fe577-f14f-4f86-a4a8-c2b85662178c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'art', 'building', 'event', 'location', 'organization', 'other', 'person', 'product']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'0': 'O',\n",
       "  '1': 'art',\n",
       "  '2': 'building',\n",
       "  '3': 'event',\n",
       "  '4': 'location',\n",
       "  '5': 'organization',\n",
       "  '6': 'other',\n",
       "  '7': 'person',\n",
       "  '8': 'product'},\n",
       " {'O': '0',\n",
       "  'art': '1',\n",
       "  'building': '2',\n",
       "  'event': '3',\n",
       "  'location': '4',\n",
       "  'organization': '5',\n",
       "  'other': '6',\n",
       "  'person': '7',\n",
       "  'product': '8'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"DFKI-SLT/few-nerd\", \"supervised\")\n",
    "ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
    "label_names = ner_feature.feature.names\n",
    "print(label_names)\n",
    "id2label = {str(i): label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "id2label, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcccc498-be11-418e-ac98-4d3c51c663bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'art',\n",
       " 'building',\n",
       " 'event',\n",
       " 'location',\n",
       " 'organization',\n",
       " 'other',\n",
       " 'person',\n",
       " 'product']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_labels = [\n",
    "    [0, 0, 1, 8],\n",
    "    [0, 5, 0, 0, 7]\n",
    "]\n",
    "dummy_predictions = [\n",
    "    [1, 0, 1, 0],\n",
    "    [0, 5, 0, 4, 4]\n",
    "]\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73d655d0-ac68-4d17-b20a-ebbc11a9ac22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'art': 1, 'building': 2, 'event': 3, 'location': 4, 'organization': 5, 'other': 6, 'person': 7, 'product': 8}\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmake_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Compute-Optimal_LoRA-Adapters_for_Language_Models/utils.py:57\u001b[0m, in \u001b[0;36mmake_confusion_matrix\u001b[0;34m(y_true, y_pred, labels, percentage, plot, size)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(conf_matrix)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_true_flat)): \u001b[38;5;66;03m# use i to loop over both, actual and predicted labels\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[43midx_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_true_flat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# true label\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     col \u001b[38;5;241m=\u001b[39m idx_dict[y_pred_flat[i]] \u001b[38;5;66;03m# pred label\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     conf_matrix[row, col] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "make_confusion_matrix(dummy_labels, dummy_predictions, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ef51a-7595-4d88-b57d-5d5a636f4ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_id = \"FacebookAI/roberta-large\"\n",
    "logs_dict[\"base_model_id\"] = base_model_id\n",
    "base_model = AutoModelForTokenClassification.from_pretrained(\n",
    "    base_model_id,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    device_map=\"auto\",\n",
    "    load_in_8bit=True\n",
    ")\n",
    "# LoRA model\n",
    "# datasets:      3 values [1%, 10%, 100%]\n",
    "# lora_rank:    10 values [1, ..., 512]\n",
    "# lora_dropout:  5 values [0, 0.1, 0.2, 0.3, 0.4]\n",
    "# lora_bias:     3 values [\"all\", \"none\", \"lora_only\"]\n",
    "# => 3 x 10 x 5 x 3 = 450 sweeps per notebook (of which 45 have rank 512 and thus take 45*3.75h=168.75 > 168h=7*24h => a bit over two weeks\n",
    "# => start with 2 dataset values (10%, 100%) and 3 rank values (2, 8, 32) => 6 sweeps\n",
    "LoRA_params_dict = {\n",
    "    \"r\": 64,\n",
    "    \"target_modules\": [\"query\", \"key\", \"value\", \"query_proj\", \"key_proj\", \"value_proj\"],\n",
    "    \"bias\": \"lora_only\",\n",
    "    \"use_rslora\": True,\n",
    "    \"task_type\": TaskType.TOKEN_CLS,\n",
    "    \"lora_dropout\": 0.2\n",
    "}\n",
    "logs_dict[\"LoRA_params_dict\"] = LoRA_params_dict\n",
    "# r =   1 => (  156681, 354476050, 0.00044)\n",
    "# r =   2 => (  304137, 354623506, 0.00086)\n",
    "# r =   4 => (  599049, 354918418, 0.00169)\n",
    "# r =   8 => ( 1188873, 355508242, 0.00334)\n",
    "# r =  16 => ( 2368521, 356687890, 0.00664)\n",
    "# r =  32 => ( 4727817, 359047186, 0.01317)\n",
    "# r =  64 => ( 9446409, 363765778, 0.02597)\n",
    "# r = 128 => (18883593, 373202962, 0.0506)\n",
    "# r = 256 => (37757961, 392077330, 0.0963)\n",
    "# r = 512 => (75506697, 429826066, 0.17567)\n",
    "config = LoraConfig(\n",
    "    # GUIDE   => https://huggingface.co/docs/peft/main/en/conceptual_guides/lora#common-lora-parameters-in-peft\n",
    "    # https://huggingface.co/docs/peft/main/en/conceptual_guides/lora#common-lora-parameters-in-peft:~:text=use_rslora%3A%20When%20set%20to%20True%2C%20uses%20Rank%2DStabilized%20LoRA%20which%20sets%20the%20adapter%20scaling%20factor\n",
    "    # https://arxiv.org/abs/2312.03732, \n",
    "    r = LoRA_params_dict[\"r\"],\n",
    "    target_modules=LoRA_params_dict[\"target_modules\"],\n",
    "    bias=LoRA_params_dict[\"bias\"],\n",
    "    use_rslora=LoRA_params_dict[\"use_rslora\"],\n",
    "    task_type=LoRA_params_dict[\"task_type\"],\n",
    "    lora_dropout=LoRA_params_dict[\"lora_dropout\"]\n",
    ")\n",
    "logs_dict[\"LoraConfig\"] = str(config)\n",
    "print(f\"LoRA config:\\n{config}\\n\")\n",
    "adapter_model = prepare_model_for_kbit_training(base_model)\n",
    "adapter_model = get_peft_model(adapter_model, config)\n",
    "print(f\"base_model type:\\n{type(base_model)}\\n\\nadapter_model type:\\n{type(adapter_model)}\")\n",
    "trainable_params, all_params = adapter_model.get_nb_trainable_parameters()\n",
    "trainable_fraction = round(trainable_params/all_params, 5)\n",
    "logs_dict[\"LoRA_model_trainable_params\"] = trainable_params\n",
    "logs_dict[\"LoRA_model_all_params\"] = all_params\n",
    "logs_dict[\"LoRA_model_trainable_fraction\"] = trainable_fraction\n",
    "print(f\"\\ntrainable parameters:\\n{trainable_params}\")\n",
    "print(f\"\\nnall parameters:\\n{all_params}\")\n",
    "print(f\"\\ntrainable fraction:\\n{trainable_fraction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330cc610-6a56-4631-b226-df0419ac07f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_prefix_space=True)\n",
    "logs_dict[\"tokenizer\"] = base_model_id\n",
    "print(f\"tokenizer is fast: {tokenizer.is_fast}\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8461807-8ab1-4253-ac37-c335c9423fa7",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad64867-2e55-45ce-b7eb-4cc521a02074",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset(\"DFKI-SLT/few-nerd\", \"supervised\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9221b549-f8f4-4ed6-9ac2-98d9429614d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "    return new_labels\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "fewnerd_all_processed = concatenate_datasets([raw_datasets[\"train\"], raw_datasets[\"validation\"], raw_datasets[\"test\"]]).map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names\n",
    ")\n",
    "fewnerd_all_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecc64b1-a3bf-4e22-9ac6-8718e78998d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter dataset by length if necessary\n",
    "trainvalid_test_splits = fewnerd_all_processed.train_test_split(test_size=0.15)\n",
    "test_split_100 = trainvalid_test_splits[\"test\"]\n",
    "test_split_10 = test_split_100.train_test_split(test_size = 0.1)[\"test\"]\n",
    "test_split_1 = test_split_100.train_test_split(test_size = 0.01)[\"test\"]\n",
    "trainvalid_split = trainvalid_test_splits[\"train\"]\n",
    "train_valid_split = trainvalid_split.train_test_split(test_size=0.15)\n",
    "valid_split_100 = train_valid_split[\"test\"]\n",
    "valid_split_10 = valid_split_100.train_test_split(test_size = 0.1)[\"test\"]\n",
    "valid_split_1 = valid_split_100.train_test_split(test_size = 0.01)[\"test\"]\n",
    "train_split_100 = train_valid_split[\"train\"]\n",
    "train_split_10 = train_split_100.train_test_split(test_size = 0.1)[\"test\"]\n",
    "train_split_1 = train_split_100.train_test_split(test_size = 0.01)[\"test\"]\n",
    "dev_train_split = train_split_100.train_test_split(test_size = 120)[\"test\"]\n",
    "dev_valid_split = valid_split_100.train_test_split(test_size = 32)[\"test\"]\n",
    "dev_test_split = test_split_100.train_test_split(test_size = 8)[\"test\"]\n",
    "fewnerd_dsd = DatasetDict({\n",
    "    \"train_100\": train_split_100,\n",
    "    \"train_10\": train_split_10,\n",
    "    \"train_1\": train_split_1,\n",
    "    \"valid_100\": valid_split_100,\n",
    "    \"valid_10\": valid_split_10,\n",
    "    \"valid_1\": valid_split_1,\n",
    "    \"test_100\": test_split_100,\n",
    "    \"test_10\": test_split_10,\n",
    "    \"test_1\": test_split_1,\n",
    "    \"train_dev\": dev_train_split,\n",
    "    \"valid_dev\": dev_valid_split,\n",
    "    \"test_dev\": dev_test_split\n",
    "})\n",
    "fewnerd_dsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847fc32c-5cb0-44d3-b6d9-45f5f2202a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"dev\" # \"100\", \"10\", \"1\", \"dev\"\n",
    "assert split in (\"100\", \"10\", \"1\", \"dev\"), f\"Split '{split}' is not a valid choice.\"\n",
    "train_split = f\"train_{split}\"\n",
    "valid_split = f\"valid_{split}\"\n",
    "test_split = f\"test_{split}\"\n",
    "train_split, valid_split, test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce12c9-fad5-4c94-af66-d77aade82d78",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b954012-9bee-4710-85ae-4c81582f5644",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize_dict = {\n",
    "    # values have been found manually via trial and error\n",
    "    \"100\": 32,\n",
    "    \"10\": 8,\n",
    "    \"1\": 1,\n",
    "    \"dev\": 1\n",
    "}\n",
    "batch_size = batchsize_dict[split]\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608c18ab-8a49-468d-9975-04bc6f0630a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd71e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data_collator([fewnerd_dsd[train_split][i] for i in [2, 3]])\n",
    "batch[\"labels\"] # As we can see, the second set of labels has been padded to the length of the first one using -100s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b560aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    fewnerd_dsd[train_split],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "valid_dataloader = DataLoader(fewnerd_dsd[valid_split], collate_fn=data_collator, batch_size=batch_size)\n",
    "train_dataloader, valid_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1911f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(adapter_model.parameters(), lr=5e-4) # 5e-4 works\n",
    "accelerator = Accelerator()\n",
    "acc_model, optimizer, train_dataloader, valid_dataloader = accelerator.prepare(\n",
    "    adapter_model,\n",
    "    optimizer,\n",
    "    train_dataloader,\n",
    "    valid_dataloader\n",
    ")\n",
    "model_folder = re.sub(\"/\", \"-\", base_model_id)\n",
    "output_dir = f\"ner_logs/{model_folder}\"\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897170de",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "logs_dict[\"num_training_steps\"] = num_training_steps\n",
    "num_warmup_steps = min(500, round(0.15 * num_update_steps_per_epoch)) # 500 or 15% of one epoch, whichever is less\n",
    "logs_dict[\"num_warmup_steps\"] = num_warmup_steps\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"cosine\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "print(f\"training_steps (all epochs):\\t{num_training_steps}\\nnum_warmup_steps (first epoch):\\t{num_warmup_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe65a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list_of_lists(list_of_lists):\n",
    "    flattened_list = []\n",
    "    for list_i in list_of_lists:\n",
    "        list_i = list_i.tolist() # handle tensors in case list_of_lists is a list of tensors\n",
    "        list_i = list(itertools.chain.from_iterable(list_i)) # flatten list_i using the standard library\n",
    "        flattened_list += list_i\n",
    "    return flattened_list\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    metrics_dict = classification_report(y_true, y_pred, digits=6, output_dict=True, zero_division=\"warn\")\n",
    "    accuracy = metrics_dict[\"accuracy\"]\n",
    "    macroavg_dict = metrics_dict[\"macro avg\"]\n",
    "    macroavg_dict[\"accuracy\"] = accuracy\n",
    "    # https://stackoverflow.com/questions/52139110/how-to-change-the-order-of-keys-in-a-python-3-5-dictionary-using-another-list-a\n",
    "    macroavg_dict_order = {k : macroavg_dict[k] for k in [\"accuracy\", \"precision\", \"recall\", \"f1-score\", \"support\"]}\n",
    "    macroavg_dict_order[\"support\"] = round(macroavg_dict_order[\"support\"]) # 134762.0\n",
    "    metrics = [f\"{key}: {macroavg_dict_order[key]}\" for key in macroavg_dict_order.keys()]\n",
    "    return metrics\n",
    "\n",
    "prof = FlopsProfiler(acc_model) # deepspeed profiler\n",
    "flops_list = []\n",
    "training_start = True\n",
    "validation_start = True\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "start_time = time.time() # start time\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    acc_model.train()\n",
    "    prof.start_profile() # start profiling\n",
    "    for batch in train_dataloader:\n",
    "        outputs = acc_model(**batch)\n",
    "        if training_start:\n",
    "            print(\"\\ntraining\")\n",
    "            print([f\"{key} shape: {list(batch[key].shape)}\" for key in list(batch.keys())])\n",
    "            print(f\"logits shape: {list(outputs['logits'].shape)}, loss: {float(outputs['loss'])}\\n\")\n",
    "            training_start = False\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "    prof.stop_profile() # stop profiling\n",
    "    total_flops = prof.get_total_flops()\n",
    "    flops_list.append(total_flops)\n",
    "    # Validation\n",
    "    acc_model.eval()\n",
    "    epoch_predictions = []\n",
    "    epoch_labels = []\n",
    "    for batch in valid_dataloader:\n",
    "        with torch.no_grad():\n",
    "            outputs = acc_model(**batch)\n",
    "        if validation_start:\n",
    "            print(\"validation\")\n",
    "            print([f\"{key} shape: {list(batch[key].shape)}\" for key in list(batch.keys())])\n",
    "            print(f\"logits shape: {list(outputs['logits'].shape)}, loss: {float(outputs['loss'])}\\n\")\n",
    "            validation_start = False\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "        assert len(predictions)==len(labels)\n",
    "        epoch_predictions.append(predictions)\n",
    "        epoch_labels.append(labels)\n",
    "    # collect both, labels and predictions, in one big list each\n",
    "    flat_epoch_labels = flatten_list_of_lists(epoch_labels)\n",
    "    flat_epoch_predictions = flatten_list_of_lists(epoch_predictions)\n",
    "    # get classification report, then log and print results\n",
    "    metrics = compute_metrics(flat_epoch_labels, flat_epoch_predictions)\n",
    "    logs_dict[f\"epoch_{epoch}_metrics\"] = metrics\n",
    "    print(metrics)\n",
    "    # # plot confusion matrix\n",
    "    make_confusion_matrix(epoch_labels, epoch_predictions, label_names)\n",
    "    # save model\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(acc_model)\n",
    "    unwrapped_model.save_pretrained(output_dir)\n",
    "    # save tokenizer\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "#\n",
    "stop_time = time.time()\n",
    "training_loop_time = str(datetime.timedelta(seconds = round(stop_time-start_time)))\n",
    "print(f\"training loop time: {training_loop_time}\")\n",
    "logs_dict[\"training_loop_time\"] = training_loop_time\n",
    "prof.end_profile() # end profiling\n",
    "logs_dict[\"flops_list\"] = flops_list\n",
    "print(flops_list)\n",
    "flops_array = np.array(flops_list)\n",
    "np.sum(flops_array), np.mean(flops_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ef406-1e1e-427a-aab7-77c818a37000",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(flat_epoch_labels), set(flat_epoch_predictions), set(flat_epoch_labels)==set(flat_epoch_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5269d6e-e4cb-49b5-93e3-0896a0f9ba4d",
   "metadata": {},
   "source": [
    "## Save logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d36a6f5-abd3-4cc5-abf6-311ed3250556",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoRA_params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d82dce9-d795-4212-ae87-a4e4e2d0075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"logsdict\"\n",
    "filename += f\"__split={split}\"\n",
    "filename += f\"__r={LoRA_params_dict['r']}\"\n",
    "filename += f\"__bias={LoRA_params_dict['bias']}\"\n",
    "filename += f\"__loradroput=0point{str(LoRA_params_dict['lora_dropout'])[2:]}\"\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f58157b-a936-4221-9271-cf8a37eedd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_dir}/{filename}.json\", \"w\") as outfile: \n",
    "\tjson.dump(logs_dict, outfile, indent=2)\n",
    "logs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afba571-3efb-4191-b61d-ea2690e61e17",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50068c2d-f2b5-44f9-9e7e-a258292e4332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load inference model\n",
    "config = PeftConfig.from_pretrained(output_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "inference_model = PeftModel.from_pretrained(base_model, output_dir).merge_and_unload()\n",
    "print(f\"type(inference_model):\\n{type(inference_model)}\\n\")\n",
    "# get inputs from text (source: https://en.wikipedia.org/wiki/Konstanz#History)\n",
    "text = \"Konstanz was the birthplace of Count Ferdinand von Zeppelin, constructor of the famous Zeppelin airships.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f987d0b-c576-4487-ab74-03c86d9ddf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "with torch.no_grad():\n",
    "    logits = inference_model(**inputs).logits\n",
    "tokens = inputs.tokens()\n",
    "predictions = torch.argmax(logits, dim=2)\n",
    "print(f\"token (prediction)\\n\")\n",
    "for token, prediction in zip(tokens, predictions[0].numpy()):\n",
    "    print(f\"{token} ({id2label[str(prediction)]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f39b0ad-1be7-4b81-9d3e-933dab612028",
   "metadata": {},
   "source": [
    "$\\checkmark$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
