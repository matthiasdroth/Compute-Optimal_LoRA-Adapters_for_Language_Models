{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cba84b5-e7e1-4e0b-b1fa-4bd18121b2ad",
   "metadata": {},
   "source": [
    "# Walkthrough\n",
    "https://docs.wandb.ai/guides/sweeps/walkthrough\n",
    "\n",
    "This page shows how to define, initialize, and run a sweep. There are four main steps:\n",
    "1. [Set up your training code](https://docs.wandb.ai/guides/sweeps/walkthrough#set-up-your-training-code)\n",
    "1. [Define the search space with a sweep configuration](https://docs.wandb.ai/guides/sweeps/walkthrough#define-the-search-space-with-a-sweep-configuration)\n",
    "1. [Initialize the sweep](https://docs.wandb.ai/guides/sweeps/walkthrough#initialize-the-sweep)\n",
    "1. [Start the sweep agent](https://docs.wandb.ai/guides/sweeps/walkthrough#start-the-sweep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c29ae836-97bf-40fe-9acd-9bb223ee9ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: wp16bmys\n",
      "Sweep URL: https://wandb.ai/mdroth/ner_fewnerd_lora/sweeps/wp16bmys\n",
      "number of sweeps: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hakczpez with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a59wa9e6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cswrutgo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tdlz7ujh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 82o6h4i8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yc42akpp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mltbayzi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l5b803m5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cglapvie with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9g9ogm61 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tg0wl3w5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uoumtz4b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qou81ze5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dq6wbf2h with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hacq43o4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1yc825id with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "# Import the W&B Python Library and log into W&B\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "# define training function (args: config, and optionally more)\n",
    "def training(config, sweep_index):\n",
    "    score = len(config.lora_bias)**3 + config.lora_rank\n",
    "    print(sweep_index)\n",
    "    return score, sweep_index+1\n",
    "\n",
    "sweep_index = 1\n",
    "project = \"ner_fewnerd_lora\"\n",
    "\n",
    "# define the function (here: main) which the sweep agent will call (args: none)\n",
    "def main():\n",
    "    global sweep_index\n",
    "    wandb.init()\n",
    "    score, sweep_index = training(wandb.config, sweep_index)\n",
    "    wandb.log({\"score\": score})\n",
    "\n",
    "# define the hyperparameter space\n",
    "sweep_configuration = {\n",
    "    \"method\": \"grid\",\n",
    "    \"metric\": {\"goal\": \"minimize\", \"name\": \"score\"},\n",
    "    \"parameters\": {\n",
    "        \"lora_bias\": {\"values\": [\"none\", \"lora_only\"]}, #  3 values [\"none\", \"lora_only\", \"all\"]\n",
    "        \"lora_rank\": {\"values\": [1, 2]},                # 10 values [1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
    "        \"model_version\": {\"values\": [\"base\", \"large\"]}, #  2 values [\"base\", \"large\"]\n",
    "        # separate 3 sweeps by manually changing the 3 \"lora_dropout\" values [0, 0.25, 0.5]\n",
    "        \"split\": {\"values\": [\"dev\", \"1\"]}               #  4 values [\"dev\", \"1\", \"10\", \"100\"]\n",
    "        # the bottom parameter key (here: \"split\") is sweeped before above parameters\n",
    "    },\n",
    "}\n",
    "\n",
    "# declare the sweep (config and project)\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=project)\n",
    "\n",
    "count = 1 # initial value before computation of \"count\"\n",
    "for key in sweep_configuration[\"parameters\"].keys():\n",
    "    count *= len(sweep_configuration[\"parameters\"][key][\"values\"])\n",
    "#\n",
    "print(f\"number of sweeps: {count}\")\n",
    "wandb.agent(sweep_id, function=main, count=count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32397207-dfd5-4122-bde5-b3c7bf54c4e3",
   "metadata": {},
   "source": [
    "The following sections break down and explains each step in the code sample.\n",
    "\n",
    "## Set up your training code\n",
    "Define a training function that takes in hyperparameter values from `wandb.config` and uses them to train a model and return metrics.\n",
    "\n",
    "Optionally provide the name of the project where you want the output of the W&B Run to be stored (project parameter in `wandb.init`). If the project is not specified, the run is put in an \"Uncategorized\" project.\n",
    "\n",
    "> <font color=\"darkgreen\">ðŸ’¡ TIP<br>Both the sweep and the run must be in the same project. Therefore, the name you provide when you initialize W&B must match the name of the project you provide when you initialize a sweep.</font>\n",
    "\n",
    "\n",
    "```python\n",
    "# 1: Define objective/training function\n",
    "def objective(config):\n",
    "    score = config.x**3 + config.y\n",
    "    return score\n",
    "\n",
    "def main():\n",
    "    wandb.init(project=\"my-first-sweep\")\n",
    "    score = objective(wandb.config)\n",
    "    wandb.log({\"score\": score})\n",
    "```\n",
    "\n",
    "## Define the search space with a sweep configuration\n",
    "Within a dictionary, specify what hyperparameters you want to sweep over and. For more information about configuration options, see Define sweep configuration.\n",
    "\n",
    "The proceeding example demonstrates a sweep configuration that uses a random search (`\"method\":\"random\"`). The sweep will randomly select a random set of values listed in the configuration for the batch size, epoch, and the learning rate.\n",
    "\n",
    "Throughout the sweeps, W&B will maximize the metric specified in the metric key (`metric`). In the following example, W&B will maximize (`\"goal\": \"maximize\"`) the validation accuracy (`\"val_acc\"`).\n",
    "\n",
    "```python\n",
    "# 2: Define the search space\n",
    "sweep_configuration = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"goal\": \"minimize\", \"name\": \"score\"},\n",
    "    \"parameters\": {\n",
    "        \"x\": {\"max\": 0.1, \"min\": 0.01},\n",
    "        \"y\": {\"values\": [1, 3, 7]},\n",
    "    },\n",
    "}\n",
    "```\n",
    "## Initialize the sweep\n",
    "W&B uses a *Sweep Controller* to manage sweeps on the cloud (standard), locally (local) across one or more machines. For more information about Sweep Controllers, see [Search and stop algorithms locally](https://docs.wandb.ai/guides/sweeps/local-controller).\n",
    "\n",
    "A sweep identification number is returned when you initialize a sweep:\n",
    "\n",
    "```python\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"my-first-sweep\")\n",
    "```\n",
    "For more information about initializing sweeps, see [Initialize sweeps](https://docs.wandb.ai/guides/sweeps/initialize-sweeps).\n",
    "\n",
    "## Start the Sweep\n",
    "Use the `wandb.agent` API call to start a sweep.\n",
    "```python\n",
    "wandb.agent(sweep_id, function=main, count=10)\n",
    "```\n",
    "\n",
    "## Visualize results (optional)\n",
    "Open your project to see your live results in the W&B App dashboard. With just a few clicks, construct rich, interactive charts like [parallel coordinates plots](https://docs.wandb.ai/guides/app/features/panels/parallel-coordinates), [parameter importance analyzes](https://docs.wandb.ai/guides/app/features/panels/parameter-importance), and [more](https://docs.wandb.ai/guides/app/features/panels).\n",
    "\n",
    "<img style=\"text-align: center\" width=\"90%\" src=\"https://docs.wandb.ai/assets/images/quickstart_dashboard_example-ef2f7996d83febe92abee2d092dc0c12.png\" />\n",
    "\n",
    "For more information about how to visualize results, see [Visualize sweep results](https://docs.wandb.ai/guides/sweeps/visualize-sweep-results). For an example dashboard, see this sample [Sweeps Project](https://wandb.ai/anmolmann/pytorch-cnn-fashion/sweeps/pmqye6u3).\n",
    "\n",
    "## Stop the agent (optional)\n",
    "From the terminal, hit `Ctrl+c` to stop the run that the Sweep agent is currently running. To kill the agent, hit `Ctrl+c` again after the run is stopped.\n",
    "\n",
    "$\\checkmark$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
