{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cba84b5-e7e1-4e0b-b1fa-4bd18121b2ad",
   "metadata": {},
   "source": [
    "# Walkthrough\n",
    "https://docs.wandb.ai/guides/sweeps/walkthrough\n",
    "\n",
    "This page shows how to define, initialize, and run a sweep. There are four main steps:\n",
    "1. [Set up your training code](https://docs.wandb.ai/guides/sweeps/walkthrough#set-up-your-training-code)\n",
    "1. [Define the search space with a sweep configuration](https://docs.wandb.ai/guides/sweeps/walkthrough#define-the-search-space-with-a-sweep-configuration)\n",
    "1. [Initialize the sweep](https://docs.wandb.ai/guides/sweeps/walkthrough#initialize-the-sweep)\n",
    "1. [Start the sweep agent](https://docs.wandb.ai/guides/sweeps/walkthrough#start-the-sweep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c29ae836-97bf-40fe-9acd-9bb223ee9ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"method\": \"grid\",\n",
      "  \"metric\": {\n",
      "    \"goal\": \"minimize\",\n",
      "    \"name\": \"score\"\n",
      "  },\n",
      "  \"parameters\": {\n",
      "    \"model_version\": {\n",
      "      \"values\": [\n",
      "        \"base\",\n",
      "        \"large\"\n",
      "      ]\n",
      "    },\n",
      "    \"lora_rank\": {\n",
      "      \"values\": [\n",
      "        2,\n",
      "        4,\n",
      "        8\n",
      "      ]\n",
      "    },\n",
      "    \"lora_bias\": {\n",
      "      \"values\": [\n",
      "        \"none\",\n",
      "        \"lora_only\",\n",
      "        \"all\"\n",
      "      ]\n",
      "    },\n",
      "    \"split\": {\n",
      "      \"values\": [\n",
      "        \"dev\",\n",
      "        \"1\",\n",
      "        \"10\",\n",
      "        \"100\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "Create sweep with ID: d5jxz5xb\n",
      "Sweep URL: https://wandb.ai/mdroth/dummy_project/sweeps/d5jxz5xb\n",
      "number of sweeps: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b1b44rma with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 76n7ramf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gt5urx4h with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wm9cklsm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 55hyo256 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3u6dswzi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 17ikkdjo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xozqujm5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fq2pv1rz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sfetza9i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l5c6m67c with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9trtsla6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n3nurxn3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r6qsm000 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ac6kdjnc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cw5zrmss with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f89oft72 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1gj0ghvz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 89x4mohs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1m5gj9q3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wbk34ss8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mfxv36v0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2foy6f3c with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kda9dihx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o4q53dj1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: swnuwaza with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oicfv9da with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sh8fp9wh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n03y4nhk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fwdnu6ec with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pnnosix2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m1g7hai9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n9enzfi0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9g2gf5lz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rb3dbuaj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rtzb6bem with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7r9r79fn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vv23dlkd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9soon28k with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u27bmok1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lwl6m07i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nq7tcb5w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9yvyqg6e with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h7a4572d with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9p267oyg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8m837s25 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ah73q0rz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i2vbzdkk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: lora_only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n08mpr11 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l1gzg47j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zy8b4dhn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f2rg7guq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tb4ocvkm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rr0md4ot with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nu7sjh1u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3ai7jmkl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3772p3pt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0nnia6rt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: euv78onh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hziyinw0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ax3tewvn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mxeakjn7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pwyq35ef with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 257gya14 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gizry3ie with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5nsf9ati with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g3mzwwwc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0eklzx9w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1sx6e8bl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nemcxllq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xqzya56q with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mexsgfn1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_bias: all\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_rank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_version: large\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "# Import the W&B Python Library and log into W&B\n",
    "import json\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "# define training function (args: config, and optionally more)\n",
    "def training(config, sweep_index):\n",
    "    score = len(config.lora_bias)**3 + config.lora_rank\n",
    "    print(sweep_index)\n",
    "    return score, sweep_index+1\n",
    "\n",
    "sweep_index = 0\n",
    "project = \"dummy_project\"\n",
    "\n",
    "# define the function (here: main) which the sweep agent will call (args: none)\n",
    "def main():\n",
    "    global sweep_index\n",
    "    wandb.init()\n",
    "    score, sweep_index = training(wandb.config, sweep_index)\n",
    "    wandb.log({\"score\": score})\n",
    "\n",
    "# define the hyperparameter space\n",
    "sweep_configuration = {\n",
    "    \"method\": \"grid\",\n",
    "    \"metric\": {\"goal\": \"minimize\", \"name\": \"score\"},\n",
    "    \"parameters\": {\n",
    "        \"model_version\": {\"values\": [\"base\", \"large\"]},\n",
    "        \"lora_rank\": {\"values\": [2, 4, 8]},\n",
    "        \"lora_bias\": {\"values\": [\"none\", \"lora_only\", \"all\"]},\n",
    "        \"split\": {\"values\": [\"dev\", \"1\", \"10\", \"100\"]}\n",
    "    },\n",
    "}\n",
    "# model_version:  2 values [\"base\", \"large\"]\n",
    "# lora_rank:     10 values [1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
    "# lora_bias:      3 values [\"none\", \"lora_only\", \"all\"]\n",
    "# lora_dropout:   5 values [0, 0.1, 0.2, 0.3, 0.4]                 (sweep \"manually\" over lora_dropout values\n",
    "# split:          4 values [\"dev\", \"1\", \"10\", \"100\"]\n",
    "\n",
    "# make 5 separate sweeps by not sweeping over lora_dropout\n",
    "\n",
    "#print(json.dumps(sweep_configuration, indent=2))\n",
    "\n",
    "# declare the sweep (config and project)\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=project)\n",
    "\n",
    "count = 1 # initial value before computation of \"count\"\n",
    "for key in sweep_configuration[\"parameters\"].keys():\n",
    "    count *= len(sweep_configuration[\"parameters\"][key][\"values\"])\n",
    "#\n",
    "print(f\"number of sweeps: {count}\")\n",
    "wandb.agent(sweep_id, function=main, count=count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32397207-dfd5-4122-bde5-b3c7bf54c4e3",
   "metadata": {},
   "source": [
    "The following sections break down and explains each step in the code sample.\n",
    "\n",
    "## Set up your training code\n",
    "Define a training function that takes in hyperparameter values from `wandb.config` and uses them to train a model and return metrics.\n",
    "\n",
    "Optionally provide the name of the project where you want the output of the W&B Run to be stored (project parameter in `wandb.init`). If the project is not specified, the run is put in an \"Uncategorized\" project.\n",
    "\n",
    "> <font color=\"darkgreen\">💡 TIP<br>Both the sweep and the run must be in the same project. Therefore, the name you provide when you initialize W&B must match the name of the project you provide when you initialize a sweep.</font>\n",
    "\n",
    "\n",
    "```python\n",
    "# 1: Define objective/training function\n",
    "def objective(config):\n",
    "    score = config.x**3 + config.y\n",
    "    return score\n",
    "\n",
    "def main():\n",
    "    wandb.init(project=\"my-first-sweep\")\n",
    "    score = objective(wandb.config)\n",
    "    wandb.log({\"score\": score})\n",
    "```\n",
    "\n",
    "## Define the search space with a sweep configuration\n",
    "Within a dictionary, specify what hyperparameters you want to sweep over and. For more information about configuration options, see Define sweep configuration.\n",
    "\n",
    "The proceeding example demonstrates a sweep configuration that uses a random search (`\"method\":\"random\"`). The sweep will randomly select a random set of values listed in the configuration for the batch size, epoch, and the learning rate.\n",
    "\n",
    "Throughout the sweeps, W&B will maximize the metric specified in the metric key (`metric`). In the following example, W&B will maximize (`\"goal\": \"maximize\"`) the validation accuracy (`\"val_acc\"`).\n",
    "\n",
    "```python\n",
    "# 2: Define the search space\n",
    "sweep_configuration = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"goal\": \"minimize\", \"name\": \"score\"},\n",
    "    \"parameters\": {\n",
    "        \"x\": {\"max\": 0.1, \"min\": 0.01},\n",
    "        \"y\": {\"values\": [1, 3, 7]},\n",
    "    },\n",
    "}\n",
    "```\n",
    "## Initialize the sweep\n",
    "W&B uses a *Sweep Controller* to manage sweeps on the cloud (standard), locally (local) across one or more machines. For more information about Sweep Controllers, see [Search and stop algorithms locally](https://docs.wandb.ai/guides/sweeps/local-controller).\n",
    "\n",
    "A sweep identification number is returned when you initialize a sweep:\n",
    "\n",
    "```python\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"my-first-sweep\")\n",
    "```\n",
    "For more information about initializing sweeps, see [Initialize sweeps](https://docs.wandb.ai/guides/sweeps/initialize-sweeps).\n",
    "\n",
    "## Start the Sweep\n",
    "Use the `wandb.agent` API call to start a sweep.\n",
    "```python\n",
    "wandb.agent(sweep_id, function=main, count=10)\n",
    "```\n",
    "\n",
    "## Visualize results (optional)\n",
    "Open your project to see your live results in the W&B App dashboard. With just a few clicks, construct rich, interactive charts like [parallel coordinates plots](https://docs.wandb.ai/guides/app/features/panels/parallel-coordinates), [parameter importance analyzes](https://docs.wandb.ai/guides/app/features/panels/parameter-importance), and [more](https://docs.wandb.ai/guides/app/features/panels).\n",
    "\n",
    "<img style=\"text-align: center\" width=\"90%\" src=\"https://docs.wandb.ai/assets/images/quickstart_dashboard_example-ef2f7996d83febe92abee2d092dc0c12.png\" />\n",
    "\n",
    "For more information about how to visualize results, see [Visualize sweep results](https://docs.wandb.ai/guides/sweeps/visualize-sweep-results). For an example dashboard, see this sample [Sweeps Project](https://wandb.ai/anmolmann/pytorch-cnn-fashion/sweeps/pmqye6u3).\n",
    "\n",
    "## Stop the agent (optional)\n",
    "From the terminal, hit `Ctrl+c` to stop the run that the Sweep agent is currently running. To kill the agent, hit `Ctrl+c` again after the run is stopped.\n",
    "\n",
    "$\\checkmark$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
