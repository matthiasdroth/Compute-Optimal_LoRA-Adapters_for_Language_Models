{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f55bab0",
   "metadata": {},
   "source": [
    "- *It works!*\n",
    "- DONE: use `max_batchsize` from `utils`\n",
    "- DONE: make **dedicated notebook** to (i) compare `conll2003` to `fewnerd` and (ii) to bring `fewnerd` into the same format.\n",
    "- DONE: use fewnerd\n",
    "- DONE: get total flops count with **einops**\n",
    "- DONE: make custom splits\n",
    "- DONE: reorder the notebook cells:\n",
    "  - DONE: model (LoRA) and tokenizer (save peftconfig if necessary)\n",
    "  - DONE: dataset etc\n",
    "  - DONE: training, metrics and saving (tokenizer and model)\n",
    "  - DONE: inference via loading saved items (probably tokenizer, model and peftconfig – OR follow this [guide](https://huggingface.co/docs/peft/v0.9.0/en/package_reference/lora#peft.LoraModel))\n",
    "- DONE: In **Using the fine-tuned model**, [merge and unload](https://huggingface.co/docs/peft/v0.6.2/en/package_reference/tuners#peft.LoraModel.merge_and_unload) or [reinstantiate](https://huggingface.co/docs/peft/v0.6.2/en/task_guides/token-classification-lora#inference) the LoRA model!\n",
    "- DONE: adjust batch size – and if necessary epochs – for 3000 training steps `num_steps = train_instances*epochs/batch_size` $\\geq$ 3000 $\\Rightarrow$ `batch_size` $\\leq$ `train_instances*epochs/3000 = train_instances/1000` $\\Rightarrow$ `batch_size` $\\leq$ `train_instances / 1000` for `epochs = 3`<br>DONE: But do it like this:\n",
    "  - DONE: get max batch size for model (= max_batchsize_by_model)\n",
    "  - DONE: specify trainig split\n",
    "  - DONE: get max batch size for training split length (=max_batchsize_by_trainsplit)\n",
    "  - DONE: impose max batch size of 32\n",
    "  - DONE: the batch size is the minimum of these three numbers\n",
    "- build `results.json` (consider pandas series) via dict and save it. It holds: splits, specified loraconfig details, flops, metrics (per epoch)\n",
    "- add comments\n",
    "- make new notebook copy for sweep\n",
    "- Check once more the wandb [ablation study](https://wandb.ai/ayush-thakur/dl-question-bank/reports/What-s-the-Optimal-Batch-Size-to-Train-a-Neural-Network---VmlldzoyMDkyNDU) on batch sizes!\n",
    "\n",
    "## NER with `fewnerd` and LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b4b5296-cb60-4875-a7f3-96e2c0c03fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-04 23:51:53,246] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/matthias/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from peft import LoraConfig, TaskType, PeftModel, PeftConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from utils import get_max_instance, get_max_batchsize\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
    "from evaluate import load\n",
    "from tqdm.auto import tqdm\n",
    "from accelerate import Accelerator\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler, pipeline, AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification\n",
    "from huggingface_hub import login\n",
    "from torch.utils.data import DataLoader\n",
    "from deepspeed.profiling.flops_profiler import FlopsProfiler\n",
    "\n",
    "load_dotenv()\n",
    "login(token=os.getenv(\"HUGGINGFACE_API_KEY\"))\n",
    "logs_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9864ca-1c11-44bd-8bf5-b1db6cb243d5",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b5fe577-f14f-4f86-a4a8-c2b85662178c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'0': 'O',\n",
       "  '1': 'art',\n",
       "  '2': 'building',\n",
       "  '3': 'event',\n",
       "  '4': 'location',\n",
       "  '5': 'organization',\n",
       "  '6': 'other',\n",
       "  '7': 'person',\n",
       "  '8': 'product'},\n",
       " {'O': '0',\n",
       "  'art': '1',\n",
       "  'building': '2',\n",
       "  'event': '3',\n",
       "  'location': '4',\n",
       "  'organization': '5',\n",
       "  'other': '6',\n",
       "  'person': '7',\n",
       "  'product': '8'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"DFKI-SLT/few-nerd\", \"supervised\")\n",
    "ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
    "label_names = ner_feature.feature.names\n",
    "id2label = {str(i): label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "id2label, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "091ef51a-7595-4d88-b57d-5d5a636f4ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA config:\n",
      "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=<TaskType.TOKEN_CLS: 'TOKEN_CLS'>, inference_mode=False, r=64, target_modules={'key_proj', 'key', 'value', 'query', 'value_proj', 'query_proj'}, lora_alpha=8, lora_dropout=0.2, fan_in_fan_out=False, bias='lora_only', use_rslora=True, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={})\n",
      "\n",
      "base_model type:\n",
      "<class 'transformers.models.roberta.modeling_roberta.RobertaForTokenClassification'>\n",
      "\n",
      "adapter_model type:\n",
      "<class 'peft.peft_model.PeftModelForTokenClassification'>\n",
      "\n",
      "trainable parameters:\n",
      "9446409\n",
      "\n",
      "all parameters:\n",
      "363765778\n",
      "\n",
      "trainable fraction:\n",
      "0.02597\n"
     ]
    }
   ],
   "source": [
    "base_model_id = \"FacebookAI/roberta-large\"\n",
    "logs_dict[\"base_model_id\"] = base_model_id\n",
    "base_model = AutoModelForTokenClassification.from_pretrained(\n",
    "    base_model_id,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    device_map=\"auto\",\n",
    "    load_in_8bit=True\n",
    ")\n",
    "# LoRA model\n",
    "# datasets:      3 values [1%, 10%, 100%]\n",
    "# lora_rank:    10 values [1, ..., 512]\n",
    "# lora_dropout:  5 values [0, 0.1, 0.2, 0.3, 0.4]\n",
    "# lora_bias:     3 values [\"all\", \"none\", \"lora_only\"]\n",
    "# => 3 x 10 x 5 x 3 = 450 sweeps per notebook\n",
    "# => start with 2 dataset values (10%, 100%) and 3 rank values (2, 8, 32) => 6 sweeps\n",
    "LoRA_params_dict = {\n",
    "    \"r\": 64,\n",
    "    \"target_modules\": [\"query\", \"key\", \"value\", \"query_proj\", \"key_proj\", \"value_proj\"],\n",
    "    \"bias\": \"lora_only\",\n",
    "    \"use_rslora\": True,\n",
    "    \"task_type\": askType.TOKEN_CLS,\n",
    "    \"lora_dropout\": 0.2\n",
    "}\n",
    "logs_dict[\"LoRA_params_dict\"] = LoRA_params_dict\n",
    "# r =   1 => (  156681, 354476050, 0.00044)\n",
    "# r =   2 => (  304137, 354623506, 0.00086)\n",
    "# r =   4 => (  599049, 354918418, 0.00169)\n",
    "# r =   8 => ( 1188873, 355508242, 0.00334)\n",
    "# r =  16 => ( 2368521, 356687890, 0.00664)\n",
    "# r =  32 => ( 4727817, 359047186, 0.01317)\n",
    "# r =  64 => ( 9446409, 363765778, 0.02597)\n",
    "# r = 128 => (18883593, 373202962, 0.0506)\n",
    "# r = 256 => (37757961, 392077330, 0.0963)\n",
    "# r = 512 => (75506697, 429826066, 0.17567)\n",
    "config = LoraConfig(\n",
    "    # GUIDE   => https://huggingface.co/docs/peft/main/en/conceptual_guides/lora#common-lora-parameters-in-peft\n",
    "    # https://huggingface.co/docs/peft/main/en/conceptual_guides/lora#common-lora-parameters-in-peft:~:text=use_rslora%3A%20When%20set%20to%20True%2C%20uses%20Rank%2DStabilized%20LoRA%20which%20sets%20the%20adapter%20scaling%20factor\n",
    "    # https://arxiv.org/abs/2312.03732, \n",
    "    r = LoRA_params_dict[\"r\"],\n",
    "    target_modules=LoRA_params_dict[\"target_modules\"],\n",
    "    bias=LoRA_params_dict[\"bias\"],\n",
    "    use_rslora=LoRA_params_dict[\"use_rslora\"],\n",
    "    task_type=LoRA_params_dict[\"task_type\"],\n",
    "    lora_dropout=LoRA_params_dict[\"lora_dropout\"]\n",
    ")\n",
    "logs_dict[\"LoraConfig\"] = config\n",
    "print(f\"LoRA config:\\n{config}\\n\")\n",
    "adapter_model = prepare_model_for_kbit_training(base_model)\n",
    "adapter_model = get_peft_model(adapter_model, config)\n",
    "print(f\"base_model type:\\n{type(base_model)}\\n\\nadapter_model type:\\n{type(adapter_model)}\")\n",
    "trainable_params, all_params = adapter_model.get_nb_trainable_parameters()\n",
    "trainable_fraction = round(trainable_params/all_params, 5)\n",
    "logs_dict[\"LoRA_model_params\"][\"trainable_params\"] = trainable_params\n",
    "logs_dict[\"LoRA_model_params\"][\"all_params\"] = all_params\n",
    "logs_dict[\"LoRA_model_params\"][\"trainable_fraction\"] = trainable_fraction\n",
    "print(f\"\\ntrainable parameters:\\n{trainable_params}\\n\\nall parameters:\\n{all_params}\\n\\ntrainable fraction:\\n{trainable_fraction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "330cc610-6a56-4631-b226-df0419ac07f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer is fast: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaTokenizerFast(name_or_path='FacebookAI/roberta-large', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, add_prefix_space=True)\n",
    "logs_dict[\"tokenizer\"] = model_id\n",
    "print(f\"tokenizer is fast: {tokenizer.is_fast}\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8461807-8ab1-4253-ac37-c335c9423fa7",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad64867-2e55-45ce-b7eb-4cc521a02074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'fine_ner_tags'],\n",
       "        num_rows: 131767\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'fine_ner_tags'],\n",
       "        num_rows: 18824\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'fine_ner_tags'],\n",
       "        num_rows: 37648\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"DFKI-SLT/few-nerd\", \"supervised\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9221b549-f8f4-4ed6-9ac2-98d9429614d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 188239\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "    return new_labels\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "fewnerd_all_processed = concatenate_datasets([raw_datasets[\"train\"], raw_datasets[\"validation\"], raw_datasets[\"test\"]]).map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names\n",
    ")\n",
    "fewnerd_all_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cecc64b1-a3bf-4e22-9ac6-8718e78998d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train_100: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 136002\n",
       "    })\n",
       "    train_10: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 13601\n",
       "    })\n",
       "    train_1: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1361\n",
       "    })\n",
       "    valid_100: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 24001\n",
       "    })\n",
       "    valid_10: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2401\n",
       "    })\n",
       "    valid_1: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 241\n",
       "    })\n",
       "    test_100: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 28236\n",
       "    })\n",
       "    test_10: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2824\n",
       "    })\n",
       "    test_1: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 283\n",
       "    })\n",
       "    dev_train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 16\n",
       "    })\n",
       "    dev_valid: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter dataset by length if necessary\n",
    "trainvalid_test_splits = fewnerd_all_processed.train_test_split(test_size=0.15)\n",
    "test_split_100 = trainvalid_test_splits[\"test\"]\n",
    "test_split_10 = test_split_100.train_test_split(test_size = 0.1)[\"test\"]\n",
    "test_split_1 = test_split_100.train_test_split(test_size = 0.01)[\"test\"]\n",
    "trainvalid_split = trainvalid_test_splits[\"train\"]\n",
    "train_valid_split = trainvalid_split.train_test_split(test_size=0.15)\n",
    "valid_split_100 = train_valid_split[\"test\"]\n",
    "valid_split_10 = valid_split_100.train_test_split(test_size = 0.1)[\"test\"]\n",
    "valid_split_1 = valid_split_100.train_test_split(test_size = 0.01)[\"test\"]\n",
    "train_split_100 = train_valid_split[\"train\"]\n",
    "train_split_10 = train_split_100.train_test_split(test_size = 0.1)[\"test\"]\n",
    "train_split_1 = train_split_100.train_test_split(test_size = 0.01)[\"test\"]\n",
    "dev_train_split = train_split_100.train_test_split(test_size = 16)[\"test\"]\n",
    "dev_valid_split = valid_split_100.train_test_split(test_size = 4)[\"test\"]\n",
    "fewnerd_dsd = DatasetDict({\n",
    "    \"train_100\": train_split_100,\n",
    "    \"train_10\": train_split_10,\n",
    "    \"train_1\": train_split_1,\n",
    "    \"valid_100\": valid_split_100,\n",
    "    \"valid_10\": valid_split_10,\n",
    "    \"valid_1\": valid_split_1,\n",
    "    \"test_100\": test_split_100,\n",
    "    \"test_10\": test_split_10,\n",
    "    \"test_1\": test_split_1,\n",
    "    \"dev_train\": dev_train_split,\n",
    "    \"dev_valid\": dev_valid_split\n",
    "})\n",
    "fewnerd_dsd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce12c9-fad5-4c94-af66-d77aade82d78",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "608c18ab-8a49-468d-9975-04bc6f0630a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForTokenClassification(tokenizer=RobertaTokenizerFast(name_or_path='FacebookAI/roberta-large', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "}, padding=True, max_length=None, pad_to_multiple_of=None, label_pad_token_id=-100, return_tensors='pt')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd71e709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-100,    7,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    7,    8,    7,    8,    0,    0,    8,    8,    8,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0, -100],\n",
       "        [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    4,    4,\n",
       "            4,    4,    4,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator([fewnerd_dsd[\"dev_train\"][i] for i in [2, 3]])\n",
    "batch[\"labels\"] # As we can see, the second set of labels has been padded to the length of the first one using -100s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9ebf1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationModule(name: \"seqeval\", module_type: \"metric\", features: {'predictions': Sequence(feature=Value(dtype='string', id='label'), length=-1, id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='label'), length=-1, id='sequence')}, usage: \"\"\"\n",
       "Produces labelling scores along with its sufficient statistics\n",
       "from a source against one or more references.\n",
       "\n",
       "Args:\n",
       "    predictions: List of List of predicted labels (Estimated targets as returned by a tagger)\n",
       "    references: List of List of reference labels (Ground truth (correct) target values)\n",
       "    suffix: True if the IOB prefix is after type, False otherwise. default: False\n",
       "    scheme: Specify target tagging scheme. Should be one of [\"IOB1\", \"IOB2\", \"IOE1\", \"IOE2\", \"IOBES\", \"BILOU\"].\n",
       "        default: None\n",
       "    mode: Whether to count correct entity labels with incorrect I/B tags as true positives or not.\n",
       "        If you want to only count exact matches, pass mode=\"strict\". default: None.\n",
       "    sample_weight: Array-like of shape (n_samples,), weights for individual samples. default: None\n",
       "    zero_division: Which value to substitute as a metric value when encountering zero division. Should be on of 0, 1,\n",
       "        \"warn\". \"warn\" acts as 0, but the warning is raised.\n",
       "\n",
       "Returns:\n",
       "    'scores': dict. Summary of the scores for overall and per type\n",
       "        Overall:\n",
       "            'accuracy': accuracy,\n",
       "            'precision': precision,\n",
       "            'recall': recall,\n",
       "            'f1': F1 score, also known as balanced F-score or F-measure,\n",
       "        Per type:\n",
       "            'precision': precision,\n",
       "            'recall': recall,\n",
       "            'f1': F1 score, also known as balanced F-score or F-measure\n",
       "Examples:\n",
       "\n",
       "    >>> predictions = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
       "    >>> references = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
       "    >>> seqeval = evaluate.load(\"seqeval\")\n",
       "    >>> results = seqeval.compute(predictions=predictions, references=references)\n",
       "    >>> print(list(results.keys()))\n",
       "    ['MISC', 'PER', 'overall_precision', 'overall_recall', 'overall_f1', 'overall_accuracy']\n",
       "    >>> print(results[\"overall_f1\"])\n",
       "    0.5\n",
       "    >>> print(results[\"PER\"][\"f1\"])\n",
       "    1.0\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = load(\"seqeval\")\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ba75a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b954012-9bee-4710-85ae-4c81582f5644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/matthias/.local/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size\t1\tworks!\n",
      "Batch size\t2\tworks!\n",
      "Batch size\t4\tworks!\n",
      "Batch size\t8\tworks!\n",
      "Batch size\t16\tworks!\n",
      "Batch size\t32\tworks!\n",
      "max_batchsize_by_trainsplit:\t128\n",
      "max_batchsize_by_model:\t\t32\n",
      "max_batchsize_by_speedup:\t16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(511, 16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# largest batch size that still leads to 1000 or more steps per training epoch\n",
    "trainsplit_len = len(fewnerd_dsd[\"train_100\"])\n",
    "for i in range(20):\n",
    "    bs = 2**i\n",
    "    if trainsplit_len/bs >= 1000:\n",
    "        max_batchsize_by_trainsplit = bs\n",
    "# longest input instance\n",
    "max_instance, len_max_instance = get_max_instance(fewnerd_dsd[\"train_100\"])\n",
    "# max_batchsize (for current LoRA model)\n",
    "max_batchsize_by_model = get_max_batchsize(adapter_model, max_instance, data_collator)\n",
    "max_batchsize_by_speedup = 16 # diminishing speedup beyond batch_size=16 AND fewer loss minimization steps\n",
    "print(f\"max_batchsize_by_trainsplit:\\t{max_batchsize_by_trainsplit}\")\n",
    "print(f\"max_batchsize_by_model:\\t\\t{max_batchsize_by_model}\")\n",
    "print(f\"max_batchsize_by_speedup:\\t{max_batchsize_by_speedup}\")\n",
    "# train_100, valid_100\n",
    "# batch_size: 16 => training_time: 4:15\n",
    "batch_size = min(max_batchsize_by_trainsplit, max_batchsize_by_model, max_batchsize_by_speedup)\n",
    "logs_dict[\"batch_size\"] = batch_size\n",
    "len_max_instance, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b560aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7fdadf5ab190>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fdadf5abaf0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = batch_size\n",
    "train_dataloader = DataLoader(\n",
    "    fewnerd_dsd[\"train_100\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "valid_dataloader = DataLoader(fewnerd_dsd[\"valid_100\"], collate_fn=data_collator, batch_size=batch_size)\n",
    "train_dataloader, valid_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1911f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(adapter_model.parameters(), lr=2e-5) # also sweep learning rate!!!\n",
    "accelerator = Accelerator()\n",
    "acc_model, optimizer, train_dataloader, valid_dataloader = accelerator.prepare(\n",
    "    adapter_model,\n",
    "    optimizer,\n",
    "    train_dataloader,\n",
    "    valid_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "897170de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25503"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "logs_dict[\"num_training_steps\"] = num_training_steps\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"cosine\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "num_training_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd1fce8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_logs/FacebookAI-roberta-large\n"
     ]
    }
   ],
   "source": [
    "model_folder = re.sub(\"/\", \"-\", model_id)\n",
    "output_dir = f\"ner_logs/{model_folder}\"\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8d12525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels = labels.detach().cpu().clone().numpy()\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_labels, true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe65a0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64ef5b1c98c417695aa74ffea200e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25503 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-04 23:52:30,774] [INFO] [profiler.py:80:start_profile] Flops profiler started\n",
      "\n",
      "training\n",
      "['input_ids shape: [16, 87]', 'attention_mask shape: [16, 87]', 'labels shape: [16, 87]']\n",
      "logits shape: [16, 87, 9], loss: 1.6160242557525635\n",
      "\n",
      "validation\n",
      "['input_ids shape: [16, 87]', 'attention_mask shape: [16, 87]', 'labels shape: [16, 87]']\n",
      "logits shape: [16, 87, 9], loss: 0.19113485515117645\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/.local/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: person seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/matthias/.local/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: product seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/matthias/.local/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: organization seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/matthias/.local/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: other seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/matthias/.local/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: location seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/matthias/.local/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: art seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/matthias/.local/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: building seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/matthias/.local/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: event seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'precision': 0.8046599808257839, 'recall': 0.7586042307731368, 'f1': 0.780953675340561, 'accuracy': 0.931495019857349}\n",
      "[2024-03-05 01:23:43,526] [INFO] [profiler.py:80:start_profile] Flops profiler started\n",
      "epoch 1: {'precision': 0.82304783859188, 'recall': 0.7660670957909723, 'f1': 0.7935358906585103, 'accuracy': 0.9340684288267784}\n",
      "[2024-03-05 02:53:48,116] [INFO] [profiler.py:80:start_profile] Flops profiler started\n",
      "epoch 2: {'precision': 0.8238449689226891, 'recall': 0.7689910009552059, 'f1': 0.7954734564819438, 'accuracy': 0.9345037961733653}\n",
      "[2024-03-05 04:23:50,188] [INFO] [profiler.py:226:end_profile] Flops profiler finished\n",
      "[516539728129536, 517529609091072, 516501104680448]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1550570441901056, 516856813967018.7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof = FlopsProfiler(acc_model) # deepspeed profiler\n",
    "flops_list = []\n",
    "training_start = True\n",
    "validation_start = True\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    acc_model.train()\n",
    "    prof.start_profile() # start profiling\n",
    "    for batch in train_dataloader:\n",
    "        outputs = acc_model(**batch)\n",
    "        if training_start:\n",
    "            print(\"\\ntraining\")\n",
    "            print([f\"{key} shape: {list(batch[key].shape)}\" for key in list(batch.keys())])\n",
    "            print(f\"logits shape: {list(outputs['logits'].shape)}, loss: {float(outputs['loss'])}\\n\")\n",
    "            training_start = False\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "    prof.stop_profile() # stop profiling\n",
    "    total_flops = prof.get_total_flops()\n",
    "    flops_list.append(total_flops)\n",
    "    # Validation\n",
    "    acc_model.eval()\n",
    "    for batch in valid_dataloader:\n",
    "        with torch.no_grad():\n",
    "            outputs = acc_model(**batch)\n",
    "        if validation_start:\n",
    "            print(\"validation\")\n",
    "            print([f\"{key} shape: {list(batch[key].shape)}\" for key in list(batch.keys())])\n",
    "            print(f\"logits shape: {list(outputs['logits'].shape)}, loss: {float(outputs['loss'])}\\n\")\n",
    "            validation_start = False\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "        # Necessary to pad predictions and labels for being gathered\n",
    "        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
    "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "        predictions_gathered = accelerator.gather(predictions)\n",
    "        labels_gathered = accelerator.gather(labels)\n",
    "        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "    results = metric.compute()\n",
    "    print(f\"epoch {epoch}:\", {key: results[f\"overall_{key}\"] for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]})\n",
    "    # save acc_model\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(acc_model)\n",
    "    unwrapped_model.save_pretrained(output_dir)\n",
    "    # save tokenizer\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "#\n",
    "prof.end_profile() # end profiling\n",
    "logs_dict[\"flops_list\"] = flops_list\n",
    "# XXX logs_dict[\"time_to_train_and_validate\"] = ...\n",
    "print(flops_list)\n",
    "flops_array = np.array(flops_list)\n",
    "# r,   bs,   t\n",
    "# 4,    4,   12h 20min\n",
    "# 4,    8,    6h 45min\n",
    "# 4,   16,    4h 15min\n",
    "# 4,   32,    3h 25min => max_batchsize = 16, due to diminishing speedup and fewer optimization steps\n",
    "# 64,   4,   12h 20min\n",
    "# 64,   8,    6h 45min\n",
    "# 64,  16,    4h 15min\n",
    "# 64,  32,    3h 25min\n",
    "np.sum(flops_array), np.mean(flops_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afba571-3efb-4191-b61d-ea2690e61e17",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a3ff758-7f9d-4389-ad17-75f4bd39dc49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1709654254.6320229"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, datetime\n",
    "start = time.time()\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14f5aad0-7b4f-424b-9c19-0266c0ef20b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1709654259.3623605"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = time.time()\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad517f7d-6b54-4915-9f8f-5ca162842966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference is: 0:00:04.730337\n"
     ]
    }
   ],
   "source": [
    "# convert timestamps to datetime object\n",
    "dt1 = datetime.datetime.fromtimestamp(start)\n",
    "dt2 = datetime.datetime.fromtimestamp(stop)\n",
    "# difference between two timestamps in hours:minutes:seconds format\n",
    "delta = dt2 - dt1\n",
    "print('Difference is:', datetime.datetime.fromtimestamp(stop)-datetime.datetime.fromtimestamp(start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffab1f2e-3d4e-4e11-bd37-e25f3943e1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.time(0, 0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c45bcb63-f352-4d0d-a2f1-5b4638d679fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.107308387756348"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = stop-start\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9d1bfcc-d96e-430d-86a6-ec2d5b61aebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1970, 1, 1, 1, 0, 15, 107308)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.fromtimestamp(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca06c9f0-1c7e-4d8f-92ee-e5cf2d48fb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/.local/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:71: UserWarning: Merge lora module to 8-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(inference_model):\n",
      "<class 'transformers.models.roberta.modeling_roberta.RobertaForTokenClassification'>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 12440, 20542, 17920,   282,  6552,   625, 17034,    16,  1207,\n",
       "            11,     5, 22637,    15,  4326,  1180,  2376,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load inference model\n",
    "config = PeftConfig.from_pretrained(output_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "inference_model = PeftModel.from_pretrained(base_model, output_dir).merge_and_unload()\n",
    "print(f\"type(inference_model):\\n{type(inference_model)}\\n\")\n",
    "# get inputs from text\n",
    "text = \"Count Björn Bernadotte is living in the castle on Mainau Island.\" # source: https://en.wikipedia.org/wiki/Mainau#Population\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c2cae61-f815-4fa7-982c-29d54ae7fb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token (prediction)\n",
      "\n",
      "<s> (O)\n",
      "ĠCount (O)\n",
      "ĠBj (person)\n",
      "Ã¶r (product)\n",
      "n (product)\n",
      "ĠBern (person)\n",
      "ad (product)\n",
      "otte (product)\n",
      "Ġis (O)\n",
      "Ġliving (O)\n",
      "Ġin (O)\n",
      "Ġthe (O)\n",
      "Ġcastle (O)\n",
      "Ġon (O)\n",
      "ĠMain (location)\n",
      "au (location)\n",
      "ĠIsland (location)\n",
      ". (product)\n",
      "</s> (product)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = inference_model(**inputs).logits\n",
    "tokens = inputs.tokens()\n",
    "predictions = torch.argmax(logits, dim=2)\n",
    "print(f\"token (prediction)\\n\")\n",
    "for token, prediction in zip(tokens, predictions[0].numpy()):\n",
    "    print(f\"{token} ({id2label[str(prediction)]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f39b0ad-1be7-4b81-9d3e-933dab612028",
   "metadata": {},
   "source": [
    "$\\checkmark$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
